# Theory 

Isolation Forest is an anomaly detection algorithm that identifies anomalies (outliers) based on the concept of isolation. It works by isolating observations in a dataset, and since anomalies are few and different, they are easier to isolate. 

- Key Concepts: 

Anomalies: Data points that differ significantly from the majority of the data. 

Isolation: The process of separating a data point from the rest. 

Isolation Trees: The structure used to isolate points; each tree in the forest is built by recursively partitioning the data. 

- Process: 

Random Partitioning: Randomly select a feature and then randomly select a split value between the minimum and maximum values of that feature. 

Recursive Splitting: Repeat the process to form a tree structure until each point is isolated. 

Isolation Path Length: The number of splits required to isolate a point. Anomalies, being distinct, generally have shorter paths. 

 
# Anomaly Detection 
 

- Data Preparation 

from sklearn.ensemble import IsolationForest 

- Fit model with low pct 

```Python 

model = IsolationForest(contamination=0.02) 

model.fit(X) 

``` 

- Analyse anomalys 

```Python 

# view the anomaly scores 

df['anomaly_scores'] = model.decision_function(X) 

df.sort_values('anomaly_scores').head() 

 

# view the anomaly flags 

df['anomaly'] = model.predict(X) 

df.sort_values('anomaly_scores') 

 

# overlay the isolation forest detected outliers 

sns.pairplot(df.drop(columns='anomaly_scores'), hue='anomaly', palette='bright', height=2); 

``` 

- Tune model  

Fit model with higher pct 

Same  code, can view difference in the DataFrame 