# Theory 

Choose the number of clusters, K. 

Initialize K centroids randomly. 

Assign each data point to the nearest centroid. 

Update the centroids by computing the mean of all data points assigned to each centroid. 

Repeat steps 3 and 4 until convergence (when the centroids no longer change significantly) 

 

# Clustering 

- Data preparation 

from sklearn.cluster import KMeans 

- Fit multiple models 

```python

inertia_values = [] 

 

for k in range(2, 16): 

    kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42) 

    kmeans.fit(data) 

    inertia_values.append(kmeans.inertia_) 

 

# create 2 - 15 clusters, and add the intertia scores to the list 

# n_init='auto', fit's only one model, 1 initial centroid 

# randem_state garantees the same result each time the model is fit 

``` 

 

- Visualize Inertia 

```python

inertia_series = pd.Series(inertia_values, index=range(2, 16)) 

 

inertia_series.plot(marker='o') 

plt.xlabel("Number of Clusters (k)") 

plt.ylabel("Inertia") 

plt.title("Number of Clusters vs. Inertia"); 

``` 

- Fit the best models (elbow) 

```python

kmeans3 = KMeans(n_clusters=3, n_init='auto', random_state=42) 

kmeans3.fit(data) 

``` 




- Visualize the model and categorize 

```python

# DataFrame of the cluster centers 

## Can compare with data.mean() or data.describe() 

 

cluster_centers3 = pd.DataFrame(kmeans3.cluster_centers_, columns=data.columns) 

 

sns.heatmap(cluster_centers3, cmap='RdBu', annot=True); 

 

# Cluster 1 : 'Cbjuhcbaj' 

# Cluster 2 : 'Bsdcfaj' 

# Cluster 3 : 'Asdcwedwqcbaj' 

``` 

 

- Tune the model 

Engineer features, etc 

Drop columns that doesn't aggregate 

```python

data_subset = data.drop('Fat', axis=1) 

``` 

Scale the data 

```python

scaler = StandardScaler() 

scaler_ft = scaler.fit_transform(data_subset) 

data_scaled = pd.DataFrame(scaler_ft, columns=data_subset.columns) 

``` 

Fit multiple model 

Visualize inertia 

Fit the best model (elbow) 

Visualize the model and categorize 

 

- Select the best K-Means model 

assign the cluster name to each row of each model 

```python

# model 1 

model1_clusters = pd.Series(kmeans3.labels_, name='model1_clusters') 

model1_names = model1_clusters\    .map({0:'Cbjuhcbaj', 1:'Bsdcfaj', 2:'Asdcwedwqcbaj'```) 

 

model2_clusters = pd.Series(kmeans6.labels_, name='model2_clusters') 

model2_names = model2_clusters \ 

.map({0: 'High Calories + Sugar', 1: 'Typical Cereals', 2: 'High Protein',3: 'High Vitamins and Minerals', 4: 'High Sugar, Low Protein', 5: 'Low Calories + Sugar + Vitamins and Minerals'```) 

``` 

view the number of students in each cluster 

```python

model1_names.value_counts() 

model2_names.value_counts() 

``` 

view individual rows 

```python

cluster_names = pd.concat([df, model1_names, model2_names], axis=1) 

cluster_names.head() 

``` 

GroupBy Clusters: 

```python

cluster_names \ 

.groupby(['model1_clusters', 'model2_clusters'])[['books', 'tv_shows', 'video_games']].mean() 

```

Categorize the select model, suggest the best representatives 

 

- Label unseen data 

Apply the same data preparation 

Predict the data 

```python

kmeans4.predict(dataframe_newdataprepped) 

``` 